{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKADPWcFKlj3"
      },
      "source": [
        "# **1. Import Library**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgA3ERnVn84N"
      },
      "source": [
        "Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "BlmvjLY9M4Yj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "from sklearn.linear_model import Perceptron, RidgeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3YIEnAFKrKL"
      },
      "source": [
        "# **2. Memuat Dataset dari Hasil Clustering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ey3ItwTen_7E"
      },
      "source": [
        "Memuat dataset hasil clustering dari file CSV ke dalam variabel DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "GHCGNTyrM5fS"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>education_num</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>hours_per_week</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>cluster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13</td>\n",
              "      <td>1092.841202</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45189</th>\n",
              "      <td>13</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45190</th>\n",
              "      <td>13</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45191</th>\n",
              "      <td>13</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45192</th>\n",
              "      <td>13</td>\n",
              "      <td>1120.673663</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>44</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45193</th>\n",
              "      <td>13</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>45194 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       education_num  capital_gain  hours_per_week  sex  age  cluster\n",
              "0                 13   1092.841202              40    1   39        3\n",
              "1                 13      0.000000              13    1   50        0\n",
              "2                  9      0.000000              40    1   38        0\n",
              "3                  7      0.000000              40    1   53        0\n",
              "4                 13      0.000000              40    0   28        1\n",
              "...              ...           ...             ...  ...  ...      ...\n",
              "45189             13      0.000000              40    1   33        0\n",
              "45190             13      0.000000              36    0   39        1\n",
              "45191             13      0.000000              50    1   38        0\n",
              "45192             13   1120.673663              40    1   44        3\n",
              "45193             13      0.000000              60    1   35        0\n",
              "\n",
              "[45194 rows x 6 columns]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv(\"Adult Income Dataset/final_data.csv\")\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkPem5eWL2UP"
      },
      "source": [
        "# **3. Data Splitting**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYj1rl_JNI9Y"
      },
      "source": [
        "Tahap Data Splitting bertujuan untuk memisahkan dataset menjadi dua bagian: data latih (training set) dan data uji (test set)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = data.drop('cluster', axis=1)\n",
        "y = data['cluster']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>education_num</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>hours_per_week</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13</td>\n",
              "      <td>1092.841202</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45189</th>\n",
              "      <td>13</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45190</th>\n",
              "      <td>13</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45191</th>\n",
              "      <td>13</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45192</th>\n",
              "      <td>13</td>\n",
              "      <td>1120.673663</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45193</th>\n",
              "      <td>13</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>45194 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       education_num  capital_gain  hours_per_week  sex  age\n",
              "0                 13   1092.841202              40    1   39\n",
              "1                 13      0.000000              13    1   50\n",
              "2                  9      0.000000              40    1   38\n",
              "3                  7      0.000000              40    1   53\n",
              "4                 13      0.000000              40    0   28\n",
              "...              ...           ...             ...  ...  ...\n",
              "45189             13      0.000000              40    1   33\n",
              "45190             13      0.000000              36    0   39\n",
              "45191             13      0.000000              50    1   38\n",
              "45192             13   1120.673663              40    1   44\n",
              "45193             13      0.000000              60    1   35\n",
              "\n",
              "[45194 rows x 5 columns]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        3\n",
              "1        0\n",
              "2        0\n",
              "3        0\n",
              "4        1\n",
              "        ..\n",
              "45189    0\n",
              "45190    1\n",
              "45191    0\n",
              "45192    3\n",
              "45193    0\n",
              "Name: cluster, Length: 45194, dtype: int64"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "OubAW-7ONKVj"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVPbB03CMhTT"
      },
      "source": [
        "# **4. Membangun Model Klasifikasi**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ned1pL9zMmBK"
      },
      "source": [
        "## **a. Membangun Model Klasifikasi**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAWzPOE4Nkti"
      },
      "source": [
        "Setelah memilih algoritma klasifikasi yang sesuai, langkah selanjutnya adalah melatih model menggunakan data latih.\n",
        "\n",
        "Berikut adalah rekomendasi tahapannya.\n",
        "1. Pilih algoritma klasifikasi yang sesuai, seperti Logistic Regression, Decision Tree, Random Forest, atau K-Nearest Neighbors (KNN).\n",
        "2. Latih model menggunakan data latih."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "models = {\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
        "    \"Ridge Classifier\": RidgeClassifier(),\n",
        "    \"Perceptron\": Perceptron(),\n",
        "    \"Multinomial Naive Bayes\": MultinomialNB(),\n",
        "    \"Logistic Regression\": LogisticRegression(multi_class='multinomial', solver='lbfgs'),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "trained_models = {}\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    trained_models[model_name] = model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "for model_name, model in trained_models.items():\n",
        "    joblib.dump(model, f'Original Model/{model_name}_trained.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seYoHNY3XU1y"
      },
      "source": [
        "#### Penjelasan Algoritma Klasifikasi Multi-Kelas\n",
        "\n",
        "1. **K-Nearest Neighbors (KNN)**: Algoritma non-parametrik yang mengklasifikasikan data berdasarkan kedekatannya dengan titik data lain. Klasifikasi ditentukan oleh suara terbanyak dari k tetangga terdekat.\n",
        "\n",
        "2. **Ridge Classifier**: Varian regresi linear yang menerapkan regularisasi L2 untuk mengurangi kompleksitas model, cocok untuk klasifikasi multi-kelas.\n",
        "\n",
        "3. **Perceptron**: Model jaringan syaraf yang memperbarui bobot berdasarkan kesalahan prediksi, efektif untuk pemisahan kelas yang dapat dipisahkan secara linear.\n",
        "\n",
        "4. **Multinomial Naive Bayes**: Algoritma probabilistik yang menghitung probabilitas kelas berdasarkan frekuensi fitur, cocok untuk data teks dan klasifikasi multi-kelas.\n",
        "\n",
        "5. **Logistic Regression**: Model regresi yang memprediksi probabilitas kelas menggunakan pendekatan softmax, dapat menangani lebih dari dua kelas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ergzChZFEL-O"
      },
      "source": [
        "## **b. Evaluasi Model Klasifikasi**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOm68u-7NpLT"
      },
      "source": [
        "Berikut adalah **rekomendasi** tahapannya.\n",
        "1. Lakukan prediksi menggunakan data uji.\n",
        "2. Hitung metrik evaluasi seperti Accuracy dan F1-Score (Opsional: Precision dan Recall).\n",
        "3. Buat confusion matrix untuk melihat detail prediksi benar dan salah."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "tMq4QAssNLip"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-Nearest Neighbors Total Accuracy: 0.9455\n",
            "K-Nearest Neighbors Weighted F1 Score: 0.9284\n",
            "K-Nearest Neighbors Precision: 0.9296\n",
            "K-Nearest Neighbors Recall: 0.9304\n",
            "K-Nearest Neighbors Confusion Matrix:\n",
            "[[5323  128    0    0]\n",
            " [ 360 2456    0    0]\n",
            " [   0    0   79  107]\n",
            " [   0    0   34  552]]\n",
            "K-Nearest Neighbors Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.98      0.96      5451\n",
            "           1       0.95      0.87      0.91      2816\n",
            "           2       0.70      0.42      0.53       186\n",
            "           3       0.84      0.94      0.89       586\n",
            "\n",
            "    accuracy                           0.93      9039\n",
            "   macro avg       0.86      0.80      0.82      9039\n",
            "weighted avg       0.93      0.93      0.93      9039\n",
            "\n",
            "------------------------------------------------------------\n",
            "Ridge Classifier Total Accuracy: 0.9805\n",
            "Ridge Classifier Weighted F1 Score: 0.9695\n",
            "Ridge Classifier Precision: 0.9601\n",
            "Ridge Classifier Recall: 0.9794\n",
            "Ridge Classifier Confusion Matrix:\n",
            "[[5451    0    0    0]\n",
            " [   0 2816    0    0]\n",
            " [   0  123    0   63]\n",
            " [   0    0    0  586]]\n",
            "Ridge Classifier Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      5451\n",
            "           1       0.96      1.00      0.98      2816\n",
            "           2       0.00      0.00      0.00       186\n",
            "           3       0.90      1.00      0.95       586\n",
            "\n",
            "    accuracy                           0.98      9039\n",
            "   macro avg       0.72      0.75      0.73      9039\n",
            "weighted avg       0.96      0.98      0.97      9039\n",
            "\n",
            "------------------------------------------------------------\n",
            "Perceptron Total Accuracy: 0.9797\n",
            "Perceptron Weighted F1 Score: 0.9698\n",
            "Perceptron Precision: 0.9633\n",
            "Perceptron Recall: 0.9785\n",
            "Perceptron Confusion Matrix:\n",
            "[[5444    0    0    7]\n",
            " [   0 2815    0    1]\n",
            " [   0    0    0  186]\n",
            " [   0    0    0  586]]\n",
            "Perceptron Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      5451\n",
            "           1       1.00      1.00      1.00      2816\n",
            "           2       0.00      0.00      0.00       186\n",
            "           3       0.75      1.00      0.86       586\n",
            "\n",
            "    accuracy                           0.98      9039\n",
            "   macro avg       0.69      0.75      0.71      9039\n",
            "weighted avg       0.96      0.98      0.97      9039\n",
            "\n",
            "------------------------------------------------------------\n",
            "Multinomial Naive Bayes Total Accuracy: 0.8821\n",
            "Multinomial Naive Bayes Weighted F1 Score: 0.8738\n",
            "Multinomial Naive Bayes Precision: 0.8997\n",
            "Multinomial Naive Bayes Recall: 0.8818\n",
            "Multinomial Naive Bayes Confusion Matrix:\n",
            "[[5451    0    0    0]\n",
            " [ 985 1831    0    0]\n",
            " [   0    0  103   83]\n",
            " [   0    0    0  586]]\n",
            "Multinomial Naive Bayes Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      1.00      0.92      5451\n",
            "           1       1.00      0.65      0.79      2816\n",
            "           2       1.00      0.55      0.71       186\n",
            "           3       0.88      1.00      0.93       586\n",
            "\n",
            "    accuracy                           0.88      9039\n",
            "   macro avg       0.93      0.80      0.84      9039\n",
            "weighted avg       0.90      0.88      0.87      9039\n",
            "\n",
            "------------------------------------------------------------\n",
            "Logistic Regression Total Accuracy: 0.9853\n",
            "Logistic Regression Weighted F1 Score: 0.9808\n",
            "Logistic Regression Precision: 0.9857\n",
            "Logistic Regression Recall: 0.9843\n",
            "Logistic Regression Confusion Matrix:\n",
            "[[5451    0    0    0]\n",
            " [   0 2816    0    0]\n",
            " [   0    0   49  137]\n",
            " [   0    0    5  581]]\n",
            "Logistic Regression Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      5451\n",
            "           1       1.00      1.00      1.00      2816\n",
            "           2       0.91      0.26      0.41       186\n",
            "           3       0.81      0.99      0.89       586\n",
            "\n",
            "    accuracy                           0.98      9039\n",
            "   macro avg       0.93      0.81      0.82      9039\n",
            "weighted avg       0.99      0.98      0.98      9039\n",
            "\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for model_name, model in trained_models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    train_accuracy = accuracy_score(y_train, model.predict(X_train))\n",
        "    test_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    total_accuracy = (train_accuracy + test_accuracy) / 2\n",
        "\n",
        "    print(f'{model_name} Total Accuracy: {total_accuracy:.4f}')\n",
        "    print(f'{model_name} Weighted F1 Score: {f1:.4f}')\n",
        "    print(f'{model_name} Precision: {precision:.4f}')\n",
        "    print(f'{model_name} Recall: {recall:.4f}')\n",
        "    print(f'{model_name} Confusion Matrix:\\n{conf_matrix}')\n",
        "    print(f'{model_name} Classification Report:')\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print('-' * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph9yIYDXEPuB"
      },
      "source": [
        "## **c. Tuning Model Klasifikasi (Optional)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Bikx3LINv5e"
      },
      "source": [
        "Gunakan GridSearchCV, RandomizedSearchCV, atau metode lainnya untuk mencari kombinasi hyperparameter terbaik"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "winbFzb8NL95"
      },
      "outputs": [],
      "source": [
        "param_grids = {\n",
        "    \"K-Nearest Neighbors\": {\n",
        "        'n_neighbors': [3, 5, 7, 10],\n",
        "        'weights': ['uniform', 'distance'],\n",
        "        'algorithm': ['auto', 'ball_tree', 'kd_tree']\n",
        "    },\n",
        "    \"Ridge Classifier\": {\n",
        "        'alpha': [0.01, 0.1, 1.0, 10.0, 100.0]\n",
        "    },\n",
        "    \"Perceptron\": {\n",
        "        'max_iter': [1000, 2000, 3000],\n",
        "        'tol': [1e-3, 1e-4, 1e-5],\n",
        "        'eta0': [0.01, 0.1, 0.5]\n",
        "    },\n",
        "    \"Multinomial Naive Bayes\": {\n",
        "        'alpha': [0.1, 1.0, 10.0]\n",
        "    },\n",
        "    \"Logistic Regression\": {\n",
        "        'C': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
        "        'max_iter': [100, 200, 300]\n",
        "    }\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-Nearest Neighbors Best Parameters: {'algorithm': 'ball_tree', 'n_neighbors': 3, 'weights': 'distance'}\n",
            "K-Nearest Neighbors Cross-Validation Accuracy Score: 0.9313\n",
            "K-Nearest Neighbors Cross-Validation F1 Score: 0.9409\n",
            "------------------------------------------------------------\n",
            "Ridge Classifier Best Parameters: {'alpha': 0.01}\n",
            "Ridge Classifier Cross-Validation Accuracy Score: 0.9816\n",
            "Ridge Classifier Cross-Validation F1 Score: 0.9727\n",
            "------------------------------------------------------------\n",
            "Perceptron Best Parameters: {'eta0': 0.1, 'max_iter': 1000, 'tol': 0.001}\n",
            "Perceptron Cross-Validation Accuracy Score: 0.9780\n",
            "Perceptron Cross-Validation F1 Score: 0.9737\n",
            "------------------------------------------------------------\n",
            "Multinomial Naive Bayes Best Parameters: {'alpha': 0.1}\n",
            "Multinomial Naive Bayes Cross-Validation Accuracy Score: 0.8826\n",
            "Multinomial Naive Bayes Cross-Validation F1 Score: 0.8745\n",
            "------------------------------------------------------------\n",
            "Logistic Regression Best Parameters: {'C': 100.0, 'max_iter': 200}\n",
            "Logistic Regression Cross-Validation Accuracy Score: 0.9952\n",
            "Logistic Regression Cross-Validation F1 Score: 1.0000\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "best_models = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    grid_search = GridSearchCV(\n",
        "        model, \n",
        "        param_grids[model_name], \n",
        "        cv=5, \n",
        "        scoring=['accuracy', 'f1_weighted'], \n",
        "        refit='accuracy',\n",
        "        return_train_score=True\n",
        "    )\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    best_models[model_name] = grid_search.best_estimator_\n",
        "\n",
        "    cv_scores = cross_val_score(best_models[model_name], X_train, y_train, cv=5, scoring='f1_weighted')\n",
        "    print(f'{model_name} Best Parameters: {grid_search.best_params_}')\n",
        "    print(f'{model_name} Cross-Validation Accuracy Score: {grid_search.cv_results_[\"mean_test_accuracy\"].mean():.4f}')\n",
        "    print(f'{model_name} Cross-Validation F1 Score: {cv_scores.mean():.4f}')\n",
        "    print('-' * 60)\n",
        "\n",
        "    joblib.dump(best_models[model_name], f'Tuning Model/{model_name}_best.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hE7pqlEPEYzI"
      },
      "source": [
        "## **d. Evaluasi Model Klasifikasi setelah Tuning (Optional)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feaPESoeN0zz"
      },
      "source": [
        "Berikut adalah rekomendasi tahapannya.\n",
        "1. Gunakan model dengan hyperparameter terbaik.\n",
        "2. Hitung ulang metrik evaluasi untuk melihat apakah ada peningkatan performa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "HTXZRvEeNMb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-Nearest Neighbors Total Accuracy: 0.9476\n",
            "K-Nearest Neighbors Weighted F1 Score: 0.9464\n",
            "K-Nearest Neighbors Precision: 0.9470\n",
            "K-Nearest Neighbors Recall: 0.9476\n",
            "K-Nearest Neighbors Confusion Matrix:\n",
            "[[5339  112    0    0]\n",
            " [ 244 2572    0    0]\n",
            " [   0    0   98   88]\n",
            " [   0    0   30  556]]\n",
            "K-Nearest Neighbors Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97      5451\n",
            "           1       0.96      0.91      0.94      2816\n",
            "           2       0.77      0.53      0.62       186\n",
            "           3       0.86      0.95      0.90       586\n",
            "\n",
            "    accuracy                           0.95      9039\n",
            "   macro avg       0.89      0.84      0.86      9039\n",
            "weighted avg       0.95      0.95      0.95      9039\n",
            "\n",
            "------------------------------------------------------------\n",
            "Ridge Classifier Total Accuracy: 0.9794\n",
            "Ridge Classifier Weighted F1 Score: 0.9695\n",
            "Ridge Classifier Precision: 0.9601\n",
            "Ridge Classifier Recall: 0.9794\n",
            "Ridge Classifier Confusion Matrix:\n",
            "[[5451    0    0    0]\n",
            " [   0 2816    0    0]\n",
            " [   0  123    0   63]\n",
            " [   0    0    0  586]]\n",
            "Ridge Classifier Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      5451\n",
            "           1       0.96      1.00      0.98      2816\n",
            "           2       0.00      0.00      0.00       186\n",
            "           3       0.90      1.00      0.95       586\n",
            "\n",
            "    accuracy                           0.98      9039\n",
            "   macro avg       0.72      0.75      0.73      9039\n",
            "weighted avg       0.96      0.98      0.97      9039\n",
            "\n",
            "------------------------------------------------------------\n",
            "Perceptron Total Accuracy: 0.9785\n",
            "Perceptron Weighted F1 Score: 0.9698\n",
            "Perceptron Precision: 0.9633\n",
            "Perceptron Recall: 0.9785\n",
            "Perceptron Confusion Matrix:\n",
            "[[5444    0    0    7]\n",
            " [   0 2815    0    1]\n",
            " [   0    0    0  186]\n",
            " [   0    0    0  586]]\n",
            "Perceptron Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      5451\n",
            "           1       1.00      1.00      1.00      2816\n",
            "           2       0.00      0.00      0.00       186\n",
            "           3       0.75      1.00      0.86       586\n",
            "\n",
            "    accuracy                           0.98      9039\n",
            "   macro avg       0.69      0.75      0.71      9039\n",
            "weighted avg       0.96      0.98      0.97      9039\n",
            "\n",
            "------------------------------------------------------------\n",
            "Multinomial Naive Bayes Total Accuracy: 0.8818\n",
            "Multinomial Naive Bayes Weighted F1 Score: 0.8738\n",
            "Multinomial Naive Bayes Precision: 0.8997\n",
            "Multinomial Naive Bayes Recall: 0.8818\n",
            "Multinomial Naive Bayes Confusion Matrix:\n",
            "[[5451    0    0    0]\n",
            " [ 985 1831    0    0]\n",
            " [   0    0  103   83]\n",
            " [   0    0    0  586]]\n",
            "Multinomial Naive Bayes Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      1.00      0.92      5451\n",
            "           1       1.00      0.65      0.79      2816\n",
            "           2       1.00      0.55      0.71       186\n",
            "           3       0.88      1.00      0.93       586\n",
            "\n",
            "    accuracy                           0.88      9039\n",
            "   macro avg       0.93      0.80      0.84      9039\n",
            "weighted avg       0.90      0.88      0.87      9039\n",
            "\n",
            "------------------------------------------------------------\n",
            "Logistic Regression Total Accuracy: 1.0000\n",
            "Logistic Regression Weighted F1 Score: 1.0000\n",
            "Logistic Regression Precision: 1.0000\n",
            "Logistic Regression Recall: 1.0000\n",
            "Logistic Regression Confusion Matrix:\n",
            "[[5451    0    0    0]\n",
            " [   0 2816    0    0]\n",
            " [   0    0  186    0]\n",
            " [   0    0    0  586]]\n",
            "Logistic Regression Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      5451\n",
            "           1       1.00      1.00      1.00      2816\n",
            "           2       1.00      1.00      1.00       186\n",
            "           3       1.00      1.00      1.00       586\n",
            "\n",
            "    accuracy                           1.00      9039\n",
            "   macro avg       1.00      1.00      1.00      9039\n",
            "weighted avg       1.00      1.00      1.00      9039\n",
            "\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for model_name, model in best_models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    total_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f'{model_name} Total Accuracy: {total_accuracy:.4f}')\n",
        "    print(f'{model_name} Weighted F1 Score: {f1:.4f}')\n",
        "    print(f'{model_name} Precision: {precision:.4f}')\n",
        "    print(f'{model_name} Recall: {recall:.4f}')\n",
        "    print(f'{model_name} Confusion Matrix:\\n{conf_matrix}')\n",
        "    print(f'{model_name} Classification Report:')\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print('-' * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRsOdm4uEgAW"
      },
      "source": [
        "## **e. Analisis Hasil Evaluasi Model Klasifikasi**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hm3BhSi6N4_l"
      },
      "source": [
        "Berikut adalah **rekomendasi** tahapannya.\n",
        "1. Bandingkan hasil evaluasi sebelum dan setelah tuning (jika dilakukan).\n",
        "2. Identifikasi kelemahan model, seperti:\n",
        "  - Precision atau Recall rendah untuk kelas tertentu.\n",
        "  - Apakah model mengalami overfitting atau underfitting?\n",
        "3. Berikan rekomendasi tindakan lanjutan, seperti mengumpulkan data tambahan atau mencoba algoritma lain jika hasil belum memuaskan."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Evaluasi Model Sebelum dan Setelah Tuning\n",
        "\n",
        "#### Hasil Evaluasi Model\n",
        "\n",
        "| Model                     | Total Accuracy | Weighted F1 Score | Precision | Recall |\n",
        "|---------------------------|----------------|--------------------|-----------|--------|\n",
        "| K-Nearest Neighbors (Sebelum) | 0.9455         | 0.9284             | 0.9296    | 0.9304 |\n",
        "| K-Nearest Neighbors (Setelah) | 0.9476         | 0.9464             | 0.9470    | 0.9476 |\n",
        "| Ridge Classifier (Sebelum)     | 0.9805         | 0.9695             | 0.9601    | 0.9794 |\n",
        "| Ridge Classifier (Setelah)     | 0.9794         | 0.9695             | 0.9601    | 0.9794 |\n",
        "| Perceptron (Sebelum)           | 0.9797         | 0.9698             | 0.9633    | 0.9785 |\n",
        "| Perceptron (Setelah)           | 0.9785         | 0.9698             | 0.9633    | 0.9785 |\n",
        "| Multinomial Naive Bayes (Sebelum)| 0.8821        | 0.8738             | 0.8997    | 0.8818 |\n",
        "| Multinomial Naive Bayes (Setelah)| 0.8818        | 0.8738             | 0.8997    | 0.8818 |\n",
        "| Logistic Regression (Sebelum)  | 0.9853         | 0.9808             | 0.9857    | 0.9843 |\n",
        "| Logistic Regression (Setelah)   | 1.0000         | 1.0000             | 1.0000    | 1.0000 |\n",
        "\n",
        "#### Identifikasi Kelemahan Model\n",
        "\n",
        "1. **K-Nearest Neighbors**\n",
        "   - **Kelemahan**: Recall untuk kelas 2 (0.53) menunjukkan model kesulitan mengklasifikasikan kelas ini.\n",
        "   - **Overfitting/Underfitting**: Model mengalami sedikit overfitting, dengan penurunan yang kecil dalam total akurasi setelah tuning.\n",
        "\n",
        "2. **Ridge Classifier**\n",
        "   - **Kelemahan**: Tidak ada kelemahan yang signifikan, tetapi recall untuk kelas 2 (0.00) menunjukkan model tidak mampu mendeteksi kelas ini sama sekali.\n",
        "   - **Overfitting/Underfitting**: Model stabil, tanpa indikasi overfitting.\n",
        "\n",
        "3. **Perceptron**\n",
        "   - **Kelemahan**: Tidak dapat mendeteksi kelas 2 (0.00), meskipun akurasi total tinggi.\n",
        "   - **Overfitting/Underfitting**: Model stabil, tanpa indikasi overfitting.\n",
        "\n",
        "4. **Multinomial Naive Bayes**\n",
        "   - **Kelemahan**: Kelas 1 memiliki recall rendah (0.65), menunjukkan kesulitan model dalam mendeteksi kelas ini.\n",
        "   - **Overfitting/Underfitting**: Model mungkin mengalami sedikit underfitting.\n",
        "\n",
        "5. **Logistic Regression**\n",
        "   - **Kelemahan**: Kelas 2 memiliki recall rendah (0.26) sebelum tuning, tetapi akurasi sempurna setelah tuning.\n",
        "   - **Overfitting/Underfitting**: Tidak ada kelemahan yang signifikan setelah tuning, menunjukkan model dapat mendeteksi semua kelas dengan baik.\n",
        "\n",
        "#### Rekomendasi Tindakan Lanjutan\n",
        "1. **Pengumpulan Data Tambahan**: Disarankan untuk mengumpulkan lebih banyak data untuk kelas yang sulit (misalnya, kelas 2) agar model dapat belajar dari variasi data yang lebih besar.\n",
        "2. **Mencoba Algoritma Lain**: Pertimbangkan untuk mencoba algoritma lain yang mungkin lebih baik dalam menangani imbalan kelas yang tidak seimbang, seperti Random Forest atau Gradient Boosting.\n",
        "3. **Penyesuaian Hyperparameter**: Lanjutkan penyesuaian hyperparameter pada model untuk meningkatkan kinerja, terutama untuk model yang menunjukkan kelemahan dalam mengidentifikasi kelas tertentu.\n",
        "\n",
        "Dengan evaluasi ini, semoga dapat meningkatkan model lebih lanjut untuk mencapai hasil yang lebih baik dan lebih konsisten."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
